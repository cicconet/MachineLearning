{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 28\n",
    "n_channels = 1\n",
    "\n",
    "def get_batch(n, phase='train'):\n",
    "    if phase == 'train':\n",
    "        data_path = '/home/cicconet/Development/MachineLearning/MNIST/Train'\n",
    "        n_categories = 10\n",
    "        n_imgs_per_category = 1000\n",
    "    elif phase == 'test':\n",
    "        data_path = '/home/cicconet/Development/MachineLearning/MNIST/Test'\n",
    "        n_categories = 10\n",
    "        n_imgs_per_category = 100\n",
    "    \n",
    "    a_batch = np.zeros((n, n_channels, im_size, im_size))\n",
    "    b_batch = np.zeros((n, n_channels, im_size, im_size))\n",
    "#     y_batch = np.zeros((n, 2))\n",
    "    y_batch = np.zeros((n, ))\n",
    "    for j in range(n//2):\n",
    "        # same category\n",
    "        category = np.random.randint(n_categories)\n",
    "        ind_a = np.random.randint(n_imgs_per_category)\n",
    "        ind_b = np.random.randint(n_imgs_per_category)\n",
    "        im_a = io.imread('%s/%d/Image%05d.png' % (data_path, category, ind_a)).astype('double')/255\n",
    "        im_b = io.imread('%s/%d/Image%05d.png' % (data_path, category, ind_b)).astype('double')/255\n",
    "\n",
    "        a_batch[2*j,:,:,:] = np.expand_dims(im_a, 0)\n",
    "        b_batch[2*j,:,:,:] = np.expand_dims(im_b, 0)\n",
    "#         y_batch[2*j,0] = 1\n",
    "        y_batch[2*j] = 0\n",
    "\n",
    "        # diff categories\n",
    "        category_a = np.random.randint(n_categories)\n",
    "        category_b = category_a\n",
    "        while category_b == category_a:\n",
    "            category_b = np.random.randint(n_categories)\n",
    "        ind_a = np.random.randint(n_imgs_per_category)\n",
    "        ind_b = np.random.randint(n_imgs_per_category)\n",
    "        im_a = io.imread('%s/%d/Image%05d.png' % (data_path, category_a, ind_a)).astype('double')/255\n",
    "        im_b = io.imread('%s/%d/Image%05d.png' % (data_path, category_b, ind_b)).astype('double')/255\n",
    "\n",
    "        a_batch[2*j+1,:,:,:] = np.expand_dims(im_a, 0)\n",
    "        b_batch[2*j+1,:,:,:] = np.expand_dims(im_b, 0)\n",
    "#         y_batch[2*j+1,1] = 1\n",
    "        y_batch[2*j+1] = 1\n",
    "\n",
    "    return a_batch, b_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "A, B, Y = get_batch(n)\n",
    "\n",
    "fig = plt.figure(figsize=(n,2))\n",
    "for i in range(n):\n",
    "#     im_a, im_b, y = np.mean(A[i,:,:,:], axis=0), np.mean(B[i,:,:,:], axis=0), np.argmax(Y[i,:])\n",
    "    im_a, im_b, y = np.mean(A[i,:,:,:], axis=0), np.mean(B[i,:,:,:], axis=0), Y[i]\n",
    "    plt.subplot(2, n, 1+i)\n",
    "    plt.imshow(im_a, cmap='gray'); plt.axis('off')\n",
    "    plt.title('same' if y == 0 else 'diff')\n",
    "    plt.subplot(2, n, n+1+i)\n",
    "    plt.imshow(im_b, cmap='gray'); plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "embed_dim = 64\n",
    "\n",
    "class CNNBranch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNBranch, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(n_channels, 6, 5) # n chan in, n chan out, kernel size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "cnn_branch = CNNBranch()\n",
    "A, B, Y = get_batch(n)\n",
    "A, B, Y = torch.from_numpy(A).float(), torch.from_numpy(B).float(), torch.from_numpy(Y).long()\n",
    "print(A.shape, B.shape, Y.shape)\n",
    "print(cnn_branch(A).shape, cnn_branch(B).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.cnn_branch = CNNBranch()\n",
    "        self.fc = nn.Linear(embed_dim, n_classes)\n",
    "\n",
    "    def forward(self, x_a, x_b):\n",
    "        embed_a = self.cnn_branch(x_a)\n",
    "        embed_b = self.cnn_branch(x_b)\n",
    "        merge = torch.abs(torch.sub(embed_a, embed_b))\n",
    "#         return F.softmax(self.fc(merge),dim=1)\n",
    "        return self.fc(merge)\n",
    "    \n",
    "siamese_net = SiameseNet()\n",
    "prediction = siamese_net(A, B)\n",
    "print(prediction.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(siamese_net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss = 0.0\n",
    "n_steps =10000\n",
    "\n",
    "siamese_net.to(device)\n",
    "criterion.to(device)\n",
    "for i_step in range(n_steps):\n",
    "    A, B, Y = get_batch(n)\n",
    "    A = torch.from_numpy(A).float().to(device)\n",
    "    B = torch.from_numpy(B).float().to(device)\n",
    "    Y = torch.from_numpy(Y).long().to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    prediction = siamese_net(A, B)\n",
    "    loss = criterion(prediction, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss = 0.5*running_loss+0.5*loss.item()\n",
    "    if i_step % 1000 == 999:\n",
    "        print('step', i_step+1, 'loss', running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "n_batches = 100\n",
    "with torch.no_grad():\n",
    "    for i_batch in range(n_batches):\n",
    "        A, B, Y = get_batch(n, 'test')\n",
    "        A = torch.from_numpy(A).float().to(device)\n",
    "        B = torch.from_numpy(B).float().to(device)\n",
    "        Y = torch.from_numpy(Y).long().to(device)\n",
    "        prediction = siamese_net(A, B)\n",
    "        mx, imx = torch.max(prediction,1)\n",
    "        total += len(Y)\n",
    "        correct += (imx == Y).sum().item()\n",
    "    \n",
    "print('accuracy', correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch15",
   "language": "python",
   "name": "pytorch15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
